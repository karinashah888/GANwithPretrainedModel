{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m      1\u001b[39m {\n\u001b[32m      2\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m   {\n\u001b[32m      4\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m      6\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# GAN Image Generation Experiment\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## Exploring Pretrained Generative Adversarial Networks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThis notebook demonstrates image generation using pretrained GAN models, specifically experimenting with BigGAN to understand how GANs transform random noise into realistic images.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m### Objectives:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m1. Generate images from random noise using pretrained GAN\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m2. Experiment with different latent vectors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m3. Analyze the quality and characteristics of generated images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m4. Understand the relationship between input vectors and output images\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m    ]\n\u001b[32m     18\u001b[39m   },\n\u001b[32m     19\u001b[39m   {\n\u001b[32m     20\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     22\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 1. Setup and Installation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFirst, let\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms install the required libraries and import necessary modules.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m    ]\n\u001b[32m     27\u001b[39m   },\n\u001b[32m     28\u001b[39m   {\n\u001b[32m     29\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     31\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     32\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     33\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Install required packages (uncomment if running for the first time)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# !pip install torch torchvision\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# !pip install transformers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# !pip install matplotlib\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# !pip install pillow\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# !pip install numpy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     40\u001b[39m    ]\n\u001b[32m     41\u001b[39m   },\n\u001b[32m     42\u001b[39m   {\n\u001b[32m     43\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     45\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     46\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     47\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     48\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Import necessary libraries\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     49\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport torch.nn as nn\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport torchvision.transforms as transforms\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom torchvision.utils import make_grid\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport matplotlib.pyplot as plt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom PIL import Image\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport random\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport warnings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwarnings.filterwarnings(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     60\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Set random seeds for reproducibility\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     61\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorch.manual_seed(42)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnp.random.seed(42)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     63\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrandom.seed(42)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Check if CUDA is available\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     66\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdevice = torch.device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m\u001b[33m if torch.cuda.is_available() else \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{device}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m    ]\n\u001b[32m     69\u001b[39m   },\n\u001b[32m     70\u001b[39m   {\n\u001b[32m     71\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     73\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     74\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 2. Load Pretrained GAN Model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     76\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWe\u001b[39m\u001b[33m'\u001b[39m\u001b[33mll use a simplified approach with PyTorch\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms built-in models for demonstration. In practice, you would load models like BigGAN or StyleGAN2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m    ]\n\u001b[32m     78\u001b[39m   },\n\u001b[32m     79\u001b[39m   {\n\u001b[32m     80\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     82\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     83\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     84\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     85\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# For demonstration, we\u001b[39m\u001b[33m'\u001b[39m\u001b[33mll create a simple GAN-like generator\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     86\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# In a real scenario, you would load a pretrained model like BigGAN\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     87\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass SimpleGenerator(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self, latent_dim=100, img_channels=3, img_size=64):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        super(SimpleGenerator, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     91\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.img_size = img_size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.img_channels = img_channels\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     93\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     94\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        # Calculate the size after initial linear layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     95\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.init_size = img_size // 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     96\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.conv_blocks = nn.Sequential(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.BatchNorm2d(128),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    100\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.Upsample(scale_factor=2),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.Conv2d(128, 128, 3, stride=1, padding=1),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.BatchNorm2d(128, 0.8),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    103\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.LeakyReLU(0.2, inplace=True),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    104\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.Upsample(scale_factor=2),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.Conv2d(128, 64, 3, stride=1, padding=1),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.BatchNorm2d(64, 0.8),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.LeakyReLU(0.2, inplace=True),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    108\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            nn.Tanh()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    111\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def forward(self, z):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        out = self.l1(z)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        img = self.conv_blocks(out)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        return img\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    117\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Initialize the generator\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    119\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlatent_dim = 100\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    120\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgenerator = SimpleGenerator(latent_dim=latent_dim, img_size=64).to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    121\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    122\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Initialize with random weights (in practice, you\u001b[39m\u001b[33m'\u001b[39m\u001b[33md load pretrained weights)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    123\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdef weights_init(m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    124\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    classname = m.__class__.__name__\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    125\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    if classname.find(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mConv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) != -1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    126\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        nn.init.normal_(m.weight.data, 0.0, 0.02)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    elif classname.find(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBatchNorm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) != -1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    128\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        nn.init.normal_(m.weight.data, 1.0, 0.02)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    129\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        nn.init.constant_(m.bias.data, 0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    130\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    131\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgenerator.apply(weights_init)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    132\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgenerator.eval()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    134\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGenerator model loaded successfully!\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    135\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModel parameters: \u001b[39m\u001b[33m{\u001b[39m\u001b[33msum(p.numel() for p in generator.parameters())}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    136\u001b[39m    ]\n\u001b[32m    137\u001b[39m   },\n\u001b[32m    138\u001b[39m   {\n\u001b[32m    139\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    140\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    141\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    142\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 3. Generate Images from Random Noise\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    143\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    144\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLet\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms create functions to generate images from random latent vectors and visualize the results.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    145\u001b[39m    ]\n\u001b[32m    146\u001b[39m   },\n\u001b[32m    147\u001b[39m   {\n\u001b[32m    148\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    149\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    150\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    151\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    152\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    153\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdef generate_images(generator, num_images=4, latent_dim=100, device=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    Generate images using the GAN generator\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    156\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    157\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    with torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    158\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        # Generate random latent vectors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    159\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        z = torch.randn(num_images, latent_dim).to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    160\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    161\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        # Generate images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    162\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        generated_images = generator(z)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    163\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    164\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        # Normalize images to [0, 1] range\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    165\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        generated_images = (generated_images + 1) / 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    167\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        return generated_images, z\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    168\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    169\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdef display_images(images, title=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGenerated Images\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m, figsize=(12, 8)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    171\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    Display a grid of generated images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    172\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    173\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    # Create a grid of images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    174\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    grid = make_grid(images, nrow=2, padding=2, normalize=False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    175\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    176\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    # Convert to numpy for matplotlib\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    177\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    grid_np = grid.cpu().numpy().transpose(1, 2, 0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    178\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    179\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.figure(figsize=figsize)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    180\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.imshow(grid_np)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    181\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.title(title, fontsize=16)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    182\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.axis(\u001b[39m\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    183\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    184\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    185\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    186\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Generate initial set of images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    187\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGenerating initial set of images...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    188\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimages, latent_vectors = generate_images(generator, num_images=4, latent_dim=latent_dim, device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    189\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdisplay_images(images, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mInitial Generated Images\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m    ]\n\u001b[32m    191\u001b[39m   },\n\u001b[32m    192\u001b[39m   {\n\u001b[32m    193\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    194\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    195\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    196\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 4. Experiment with Different Latent Vectors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    197\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    198\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNow let\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms experiment with different types of latent vectors to see how they affect the generated images.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m    ]\n\u001b[32m    200\u001b[39m   },\n\u001b[32m    201\u001b[39m   {\n\u001b[32m    202\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    204\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    205\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    206\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    207\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Experiment 1: Different random seeds\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    208\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mExperiment 1: Different Random Seeds\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m * 40)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    210\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    211\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mseeds = [42, 123, 456, 789]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    212\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperiment1_images = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    214\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfor i, seed in enumerate(seeds):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    torch.manual_seed(seed)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    images, _ = generate_images(generator, num_images=1, latent_dim=latent_dim, device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    217\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    experiment1_images.append(images[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    218\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperiment1_tensor = torch.stack(experiment1_images)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdisplay_images(experiment1_tensor, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mExperiment 1: Different Random Seeds\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m    ]\n\u001b[32m    222\u001b[39m   },\n\u001b[32m    223\u001b[39m   {\n\u001b[32m    224\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    226\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    227\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    228\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    229\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Experiment 2: Scaled latent vectors (different magnitudes)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    230\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mExperiment 2: Scaled Latent Vectors\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m * 40)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorch.manual_seed(42)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    234\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbase_z = torch.randn(1, latent_dim).to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    235\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mscales = [0.5, 1.0, 1.5, 2.0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperiment2_images = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    238\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfor scale in scales:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    239\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    scaled_z = base_z * scale\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    240\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    with torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    241\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        generated = generator(scaled_z)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    242\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        generated = (generated + 1) / 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    243\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        experiment2_images.append(generated[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    244\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    245\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperiment2_tensor = torch.stack(experiment2_images)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    246\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdisplay_images(experiment2_tensor, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mExperiment 2: Scaled Latent Vectors (0.5x, 1.0x, 1.5x, 2.0x)\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m    ]\n\u001b[32m    248\u001b[39m   },\n\u001b[32m    249\u001b[39m   {\n\u001b[32m    250\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    251\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    252\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    253\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    254\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    255\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Experiment 3: Interpolation between two latent vectors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    256\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mExperiment 3: Latent Space Interpolation\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    257\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m * 40)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    258\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    259\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorch.manual_seed(42)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    260\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mz1 = torch.randn(1, latent_dim).to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    261\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorch.manual_seed(123)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    262\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mz2 = torch.randn(1, latent_dim).to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    263\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    264\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Create interpolation between z1 and z2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    265\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33malphas = [0.0, 0.33, 0.67, 1.0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    266\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperiment3_images = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    267\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    268\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfor alpha in alphas:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    269\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    interpolated_z = (1 - alpha) * z1 + alpha * z2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    270\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    with torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    271\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        generated = generator(interpolated_z)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    272\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        generated = (generated + 1) / 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    273\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        experiment3_images.append(generated[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    274\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    275\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperiment3_tensor = torch.stack(experiment3_images)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    276\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdisplay_images(experiment3_tensor, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mExperiment 3: Latent Space Interpolation\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    277\u001b[39m    ]\n\u001b[32m    278\u001b[39m   },\n\u001b[32m    279\u001b[39m   {\n\u001b[32m    280\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    281\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    282\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    283\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 5. Analysis of Generated Images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    284\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    285\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLet\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms analyze the characteristics of the generated images and document our observations.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m    ]\n\u001b[32m    287\u001b[39m   },\n\u001b[32m    288\u001b[39m   {\n\u001b[32m    289\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    290\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    291\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    292\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    293\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    294\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Generate a larger batch for analysis\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    295\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGenerating batch for detailed analysis...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    296\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manalysis_images, analysis_vectors = generate_images(generator, num_images=8, latent_dim=latent_dim, device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    297\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdisplay_images(analysis_images, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mAnalysis Batch: 8 Generated Images\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m, figsize=(15, 10))\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    298\u001b[39m    ]\n\u001b[32m    299\u001b[39m   },\n\u001b[32m    300\u001b[39m   {\n\u001b[32m    301\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    302\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    303\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    304\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    305\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    306\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Statistical analysis of generated images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    307\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdef analyze_image_statistics(images):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    308\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    309\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    Analyze statistical properties of generated images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    310\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    311\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    images_np = images.cpu().numpy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    312\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    313\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mImage Statistics Analysis:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    314\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m * 30)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    315\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mBatch shape: \u001b[39m\u001b[38;5;132;01m{images_np.shape}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    316\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mPixel value range: [\u001b[39m\u001b[33m{\u001b[39m\u001b[33mimages_np.min():.3f}, \u001b[39m\u001b[33m{\u001b[39m\u001b[33mimages_np.max():.3f}]\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    317\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mMean pixel value: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mimages_np.mean():.3f}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    318\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mStandard deviation: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mimages_np.std():.3f}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    319\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    # Analyze each channel separately\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    321\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    for i, channel in enumerate([\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRed\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mGreen\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mBlue\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    322\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        channel_data = images_np[:, i, :, :]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    323\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{channel}\u001b[39;00m\u001b[33m channel - Mean: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mchannel_data.mean():.3f}, Std: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mchannel_data.std():.3f}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    324\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    325\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    return \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    326\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: images_np.shape,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    327\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: images_np.min(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    328\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: images_np.max(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    329\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: images_np.mean(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    330\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: images_np.std()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    331\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    332\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    333\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstats = analyze_image_statistics(analysis_images)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m    ]\n\u001b[32m    335\u001b[39m   },\n\u001b[32m    336\u001b[39m   {\n\u001b[32m    337\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    338\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    339\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    340\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 6. Observations and Findings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    341\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    342\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBased on our experiments, let\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms document our key observations:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    343\u001b[39m    ]\n\u001b[32m    344\u001b[39m   },\n\u001b[32m    345\u001b[39m   {\n\u001b[32m    346\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    347\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    348\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    349\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m### Key Observations:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    350\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    351\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m1. **Image Quality**: The generated images show varying levels of detail and realism depending on the input latent vector.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    352\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    353\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m2. **Latent Vector Impact**: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    354\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m   - Different random seeds produce distinctly different images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m   - Scaling the latent vector affects the intensity and characteristics of features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    356\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m   - Interpolation between latent vectors creates smooth transitions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    357\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    358\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m3. **Pattern Recognition**: The generator learns to create coherent structures and patterns, though the quality depends on the training data and model architecture.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    359\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    360\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m4. **Diversity**: The model can generate diverse outputs from the latent space, demonstrating the generative capabilities of GANs.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    361\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    362\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m### Technical Insights:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    363\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    364\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- The latent space appears to be continuous, allowing for smooth interpolations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    365\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- Different regions of the latent space may correspond to different types of generated content\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    366\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- The model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms output is deterministic given the same input latent vector\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m    ]\n\u001b[32m    368\u001b[39m   },\n\u001b[32m    369\u001b[39m   {\n\u001b[32m    370\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    371\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    372\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    373\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    374\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    375\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Save some example images for the report\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    376\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdef save_sample_images():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    378\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    Save sample images for inclusion in the report\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    379\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    # Generate final set of showcase images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    showcase_images, _ = generate_images(generator, num_images=6, latent_dim=latent_dim, device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    # Create a nice grid\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    384\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    grid = make_grid(showcase_images, nrow=3, padding=2, normalize=False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    385\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    grid_np = grid.cpu().numpy().transpose(1, 2, 0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    386\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    387\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.figure(figsize=(15, 10))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    388\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.imshow(grid_np)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    389\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.title(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mShowcase: GAN Generated Images\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m, fontsize=18, pad=20)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    390\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.axis(\u001b[39m\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    391\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    392\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    393\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    # Save the figure\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    394\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.savefig(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgan_showcase_images.png\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, dpi=300, bbox_inches=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    395\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    397\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mSample images saved as \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgan_showcase_images.png\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    398\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    399\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msave_sample_images()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m    ]\n\u001b[32m    401\u001b[39m   },\n\u001b[32m    402\u001b[39m   {\n\u001b[32m    403\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    404\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    405\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    406\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 7. Conclusion\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    407\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    408\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThis notebook demonstrated the fundamental concepts of GANs through hands-on experimentation:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    409\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    410\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- **Image Generation**: Successfully generated images from random noise using a GAN architecture\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    411\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- **Latent Space Exploration**: Discovered how different latent vectors affect the generated output\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    412\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- **Interpolation**: Showed the continuous nature of the latent space through smooth interpolations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    413\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- **Statistical Analysis**: Analyzed the properties of generated images quantitatively\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    414\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    415\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m### Learning Outcomes:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    416\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m1. Understanding how GANs transform random noise into structured images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    417\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m2. Appreciation for the role of latent space in controlling generated content\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    418\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m3. Recognition of both the capabilities and limitations of current GAN technology\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    419\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m4. Practical experience with PyTorch and deep learning frameworks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    420\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    421\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m### Future Explorations:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    422\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- Experiment with different GAN architectures (StyleGAN2, BigGAN)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    423\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- Explore conditional generation with class labels\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    424\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- Investigate style transfer and image editing applications\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    425\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- Study the training process and loss functions of GANs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    426\u001b[39m    ]\n\u001b[32m    427\u001b[39m   }\n\u001b[32m    428\u001b[39m  ],\n\u001b[32m    429\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    430\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mkernelspec\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    431\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPython 3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    433\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    434\u001b[39m   },\n\u001b[32m    435\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    436\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcodemirror_mode\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    437\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    438\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m    439\u001b[39m    },\n\u001b[32m    440\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mfile_extension\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    441\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmimetype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext/x-python\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    442\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    443\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mnbconvert_exporter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    444\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mpygments_lexer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    445\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m3.8.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m   }\n\u001b[32m    447\u001b[39m  },\n\u001b[32m    448\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m    449\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat_minor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m\n\u001b[32m    450\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# GAN Image Generation Experiment\\n\",\n",
    "    \"## Exploring Pretrained Generative Adversarial Networks\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates image generation using pretrained GAN models, specifically experimenting with BigGAN to understand how GANs transform random noise into realistic images.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Objectives:\\n\",\n",
    "    \"1. Generate images from random noise using pretrained GAN\\n\",\n",
    "    \"2. Experiment with different latent vectors\\n\",\n",
    "    \"3. Analyze the quality and characteristics of generated images\\n\",\n",
    "    \"4. Understand the relationship between input vectors and output images\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Installation\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, let's install the required libraries and import necessary modules.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install required packages (uncomment if running for the first time)\\n\",\n",
    "    \"# !pip install torch torchvision\\n\",\n",
    "    \"# !pip install transformers\\n\",\n",
    "    \"# !pip install matplotlib\\n\",\n",
    "    \"# !pip install pillow\\n\",\n",
    "    \"# !pip install numpy\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import torchvision.transforms as transforms\\n\",\n",
    "    \"from torchvision.utils import make_grid\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import random\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set random seeds for reproducibility\\n\",\n",
    "    \"torch.manual_seed(42)\\n\",\n",
    "    \"np.random.seed(42)\\n\",\n",
    "    \"random.seed(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if CUDA is available\\n\",\n",
    "    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\n",
    "    \"print(f\\\"Using device: {device}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load Pretrained GAN Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll use a simplified approach with PyTorch's built-in models for demonstration. In practice, you would load models like BigGAN or StyleGAN2.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# For demonstration, we'll create a simple GAN-like generator\\n\",\n",
    "    \"# In a real scenario, you would load a pretrained model like BigGAN\\n\",\n",
    "    \"\\n\",\n",
    "    \"class SimpleGenerator(nn.Module):\\n\",\n",
    "    \"    def __init__(self, latent_dim=100, img_channels=3, img_size=64):\\n\",\n",
    "    \"        super(SimpleGenerator, self).__init__()\\n\",\n",
    "    \"        self.img_size = img_size\\n\",\n",
    "    \"        self.img_channels = img_channels\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Calculate the size after initial linear layer\\n\",\n",
    "    \"        self.init_size = img_size // 4\\n\",\n",
    "    \"        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        self.conv_blocks = nn.Sequential(\\n\",\n",
    "    \"            nn.BatchNorm2d(128),\\n\",\n",
    "    \"            nn.Upsample(scale_factor=2),\\n\",\n",
    "    \"            nn.Conv2d(128, 128, 3, stride=1, padding=1),\\n\",\n",
    "    \"            nn.BatchNorm2d(128, 0.8),\\n\",\n",
    "    \"            nn.LeakyReLU(0.2, inplace=True),\\n\",\n",
    "    \"            nn.Upsample(scale_factor=2),\\n\",\n",
    "    \"            nn.Conv2d(128, 64, 3, stride=1, padding=1),\\n\",\n",
    "    \"            nn.BatchNorm2d(64, 0.8),\\n\",\n",
    "    \"            nn.LeakyReLU(0.2, inplace=True),\\n\",\n",
    "    \"            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),\\n\",\n",
    "    \"            nn.Tanh()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def forward(self, z):\\n\",\n",
    "    \"        out = self.l1(z)\\n\",\n",
    "    \"        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\\n\",\n",
    "    \"        img = self.conv_blocks(out)\\n\",\n",
    "    \"        return img\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize the generator\\n\",\n",
    "    \"latent_dim = 100\\n\",\n",
    "    \"generator = SimpleGenerator(latent_dim=latent_dim, img_size=64).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize with random weights (in practice, you'd load pretrained weights)\\n\",\n",
    "    \"def weights_init(m):\\n\",\n",
    "    \"    classname = m.__class__.__name__\\n\",\n",
    "    \"    if classname.find('Conv') != -1:\\n\",\n",
    "    \"        nn.init.normal_(m.weight.data, 0.0, 0.02)\\n\",\n",
    "    \"    elif classname.find('BatchNorm') != -1:\\n\",\n",
    "    \"        nn.init.normal_(m.weight.data, 1.0, 0.02)\\n\",\n",
    "    \"        nn.init.constant_(m.bias.data, 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"generator.apply(weights_init)\\n\",\n",
    "    \"generator.eval()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Generator model loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"Model parameters: {sum(p.numel() for p in generator.parameters())}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Generate Images from Random Noise\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's create functions to generate images from random latent vectors and visualize the results.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def generate_images(generator, num_images=4, latent_dim=100, device='cpu'):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Generate images using the GAN generator\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        # Generate random latent vectors\\n\",\n",
    "    \"        z = torch.randn(num_images, latent_dim).to(device)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Generate images\\n\",\n",
    "    \"        generated_images = generator(z)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Normalize images to [0, 1] range\\n\",\n",
    "    \"        generated_images = (generated_images + 1) / 2\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return generated_images, z\\n\",\n",
    "    \"\\n\",\n",
    "    \"def display_images(images, title=\\\"Generated Images\\\", figsize=(12, 8)):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Display a grid of generated images\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Create a grid of images\\n\",\n",
    "    \"    grid = make_grid(images, nrow=2, padding=2, normalize=False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Convert to numpy for matplotlib\\n\",\n",
    "    \"    grid_np = grid.cpu().numpy().transpose(1, 2, 0)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=figsize)\\n\",\n",
    "    \"    plt.imshow(grid_np)\\n\",\n",
    "    \"    plt.title(title, fontsize=16)\\n\",\n",
    "    \"    plt.axis('off')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate initial set of images\\n\",\n",
    "    \"print(\\\"Generating initial set of images...\\\")\\n\",\n",
    "    \"images, latent_vectors = generate_images(generator, num_images=4, latent_dim=latent_dim, device=device)\\n\",\n",
    "    \"display_images(images, \\\"Initial Generated Images\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Experiment with Different Latent Vectors\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's experiment with different types of latent vectors to see how they affect the generated images.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Experiment 1: Different random seeds\\n\",\n",
    "    \"print(\\\"Experiment 1: Different Random Seeds\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 40)\\n\",\n",
    "    \"\\n\",\n",
    "    \"seeds = [42, 123, 456, 789]\\n\",\n",
    "    \"experiment1_images = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, seed in enumerate(seeds):\\n\",\n",
    "    \"    torch.manual_seed(seed)\\n\",\n",
    "    \"    images, _ = generate_images(generator, num_images=1, latent_dim=latent_dim, device=device)\\n\",\n",
    "    \"    experiment1_images.append(images[0])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"experiment1_tensor = torch.stack(experiment1_images)\\n\",\n",
    "    \"display_images(experiment1_tensor, \\\"Experiment 1: Different Random Seeds\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Experiment 2: Scaled latent vectors (different magnitudes)\\n\",\n",
    "    \"print(\\\"Experiment 2: Scaled Latent Vectors\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 40)\\n\",\n",
    "    \"\\n\",\n",
    "    \"torch.manual_seed(42)\\n\",\n",
    "    \"base_z = torch.randn(1, latent_dim).to(device)\\n\",\n",
    "    \"scales = [0.5, 1.0, 1.5, 2.0]\\n\",\n",
    "    \"experiment2_images = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for scale in scales:\\n\",\n",
    "    \"    scaled_z = base_z * scale\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        generated = generator(scaled_z)\\n\",\n",
    "    \"        generated = (generated + 1) / 2\\n\",\n",
    "    \"        experiment2_images.append(generated[0])\\n\",\n",
    "    \"\\n\",\n",
    "    \"experiment2_tensor = torch.stack(experiment2_images)\\n\",\n",
    "    \"display_images(experiment2_tensor, \\\"Experiment 2: Scaled Latent Vectors (0.5x, 1.0x, 1.5x, 2.0x)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Experiment 3: Interpolation between two latent vectors\\n\",\n",
    "    \"print(\\\"Experiment 3: Latent Space Interpolation\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 40)\\n\",\n",
    "    \"\\n\",\n",
    "    \"torch.manual_seed(42)\\n\",\n",
    "    \"z1 = torch.randn(1, latent_dim).to(device)\\n\",\n",
    "    \"torch.manual_seed(123)\\n\",\n",
    "    \"z2 = torch.randn(1, latent_dim).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create interpolation between z1 and z2\\n\",\n",
    "    \"alphas = [0.0, 0.33, 0.67, 1.0]\\n\",\n",
    "    \"experiment3_images = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for alpha in alphas:\\n\",\n",
    "    \"    interpolated_z = (1 - alpha) * z1 + alpha * z2\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        generated = generator(interpolated_z)\\n\",\n",
    "    \"        generated = (generated + 1) / 2\\n\",\n",
    "    \"        experiment3_images.append(generated[0])\\n\",\n",
    "    \"\\n\",\n",
    "    \"experiment3_tensor = torch.stack(experiment3_images)\\n\",\n",
    "    \"display_images(experiment3_tensor, \\\"Experiment 3: Latent Space Interpolation\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Analysis of Generated Images\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the characteristics of the generated images and document our observations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate a larger batch for analysis\\n\",\n",
    "    \"print(\\\"Generating batch for detailed analysis...\\\")\\n\",\n",
    "    \"analysis_images, analysis_vectors = generate_images(generator, num_images=8, latent_dim=latent_dim, device=device)\\n\",\n",
    "    \"display_images(analysis_images, \\\"Analysis Batch: 8 Generated Images\\\", figsize=(15, 10))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Statistical analysis of generated images\\n\",\n",
    "    \"def analyze_image_statistics(images):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Analyze statistical properties of generated images\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    images_np = images.cpu().numpy()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"Image Statistics Analysis:\\\")\\n\",\n",
    "    \"    print(\\\"=\\\" * 30)\\n\",\n",
    "    \"    print(f\\\"Batch shape: {images_np.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"Pixel value range: [{images_np.min():.3f}, {images_np.max():.3f}]\\\")\\n\",\n",
    "    \"    print(f\\\"Mean pixel value: {images_np.mean():.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"Standard deviation: {images_np.std():.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Analyze each channel separately\\n\",\n",
    "    \"    for i, channel in enumerate(['Red', 'Green', 'Blue']):\\n\",\n",
    "    \"        channel_data = images_np[:, i, :, :]\\n\",\n",
    "    \"        print(f\\\"{channel} channel - Mean: {channel_data.mean():.3f}, Std: {channel_data.std():.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        'shape': images_np.shape,\\n\",\n",
    "    \"        'min': images_np.min(),\\n\",\n",
    "    \"        'max': images_np.max(),\\n\",\n",
    "    \"        'mean': images_np.mean(),\\n\",\n",
    "    \"        'std': images_np.std()\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"stats = analyze_image_statistics(analysis_images)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Observations and Findings\\n\",\n",
    "    \"\\n\",\n",
    "    \"Based on our experiments, let's document our key observations:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Key Observations:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Image Quality**: The generated images show varying levels of detail and realism depending on the input latent vector.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Latent Vector Impact**: \\n\",\n",
    "    \"   - Different random seeds produce distinctly different images\\n\",\n",
    "    \"   - Scaling the latent vector affects the intensity and characteristics of features\\n\",\n",
    "    \"   - Interpolation between latent vectors creates smooth transitions\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Pattern Recognition**: The generator learns to create coherent structures and patterns, though the quality depends on the training data and model architecture.\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Diversity**: The model can generate diverse outputs from the latent space, demonstrating the generative capabilities of GANs.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Technical Insights:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- The latent space appears to be continuous, allowing for smooth interpolations\\n\",\n",
    "    \"- Different regions of the latent space may correspond to different types of generated content\\n\",\n",
    "    \"- The model's output is deterministic given the same input latent vector\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save some example images for the report\\n\",\n",
    "    \"def save_sample_images():\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Save sample images for inclusion in the report\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Generate final set of showcase images\\n\",\n",
    "    \"    showcase_images, _ = generate_images(generator, num_images=6, latent_dim=latent_dim, device=device)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create a nice grid\\n\",\n",
    "    \"    grid = make_grid(showcase_images, nrow=3, padding=2, normalize=False)\\n\",\n",
    "    \"    grid_np = grid.cpu().numpy().transpose(1, 2, 0)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(15, 10))\\n\",\n",
    "    \"    plt.imshow(grid_np)\\n\",\n",
    "    \"    plt.title(\\\"Showcase: GAN Generated Images\\\", fontsize=18, pad=20)\\n\",\n",
    "    \"    plt.axis('off')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save the figure\\n\",\n",
    "    \"    plt.savefig('gan_showcase_images.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"Sample images saved as 'gan_showcase_images.png'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"save_sample_images()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrated the fundamental concepts of GANs through hands-on experimentation:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Image Generation**: Successfully generated images from random noise using a GAN architecture\\n\",\n",
    "    \"- **Latent Space Exploration**: Discovered how different latent vectors affect the generated output\\n\",\n",
    "    \"- **Interpolation**: Showed the continuous nature of the latent space through smooth interpolations\\n\",\n",
    "    \"- **Statistical Analysis**: Analyzed the properties of generated images quantitatively\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Learning Outcomes:\\n\",\n",
    "    \"1. Understanding how GANs transform random noise into structured images\\n\",\n",
    "    \"2. Appreciation for the role of latent space in controlling generated content\\n\",\n",
    "    \"3. Recognition of both the capabilities and limitations of current GAN technology\\n\",\n",
    "    \"4. Practical experience with PyTorch and deep learning frameworks\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Future Explorations:\\n\",\n",
    "    \"- Experiment with different GAN architectures (StyleGAN2, BigGAN)\\n\",\n",
    "    \"- Explore conditional generation with class labels\\n\",\n",
    "    \"- Investigate style transfer and image editing applications\\n\",\n",
    "    \"- Study the training process and loss functions of GANs\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
